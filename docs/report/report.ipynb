{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on Reverse Engineering the Mechanism of Wechat Red Envelop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generative Modeling\n",
    "For this section, we modify the diffusion model so as to learn the latent distribution behind the data and hence generate new data. The code supports running with GPU and checkpoint saving. The code is partially borrowed from the open tutorial resource published on github, and partial debugging is under the assistance of ChatGPT. We run the code on GPU of NVIDIA GeForce RTX 4070 Laptop, with the CPU of 13th Gen Intel(R) Core(TM) i9-13980HX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Code Implementaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "data = np.load('raw_data_1.npy')\n",
    "dataset = torch.Tensor(data).float()\n",
    "# 超参数设置\n",
    "num_steps = 100  # 扩散过程的时间步数\n",
    "batch_size = 256  # 每次训练的批量大小\n",
    "\n",
    "# 创建 beta 调度，模拟噪声的逐步变化\n",
    "betas = torch.linspace(-6, 6, num_steps)\n",
    "betas = torch.sigmoid(betas) * (0.5e-2 - 1e-5) + 1e-5\n",
    "\n",
    "# 计算 alpha 和相关变量\n",
    "alphas = 1 - betas\n",
    "alphas_prod = torch.cumprod(alphas, dim=0)\n",
    "alphas_prod_p = torch.cat([torch.tensor([1]).float(), alphas_prod[:-1]], 0)\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n",
    "\n",
    "# 扩散过程中的加噪声函数\n",
    "def q_x(x_0, t):\n",
    "    noise = torch.randn_like(x_0)  # 从标准正态分布中生成噪声\n",
    "    alphas_t = alphas_bar_sqrt[t]\n",
    "    alphas_l_m_t = one_minus_alphas_bar_sqrt[t]\n",
    "    return alphas_t * x_0 + alphas_l_m_t * noise\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filename):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved to {filename}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {filename}\")\n",
    "    return epoch, loss\n",
    "\n",
    "\n",
    "# 创建一个多层感知机模型，用于拟合噪声预测\n",
    "class MLPDiffusion(nn.Module):\n",
    "    def __init__(self, n_steps, num_units=128):\n",
    "        super(MLPDiffusion, self).__init__()\n",
    "        self.linears = nn.ModuleList([\n",
    "            nn.Linear(3, num_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units, num_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units, num_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units, 3),  # 输出3个维度 (x1, x2, x3)\n",
    "        ])\n",
    "        self.step_embeddings = nn.ModuleList([\n",
    "            nn.Embedding(n_steps, num_units),\n",
    "            nn.Embedding(n_steps, num_units),\n",
    "            nn.Embedding(n_steps, num_units)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        for idx, embedding_layer in enumerate(self.step_embeddings):\n",
    "            t_embedding = embedding_layer(t)\n",
    "            x = self.linears[2 * idx](x)\n",
    "            x += t_embedding\n",
    "            x = self.linears[2 * idx + 1](x)\n",
    "        return self.linears[-1](x)\n",
    "\n",
    "# 损失函数：计算模型预测的噪声与真实噪声之间的均方误差\n",
    "def diffusion_loss_fn(model, x_0, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, n_steps):\n",
    "    batch_size = x_0.shape[0]\n",
    "\n",
    "    # 随机采样一个时刻 t\n",
    "    t = torch.randint(0, n_steps, size=(batch_size,))\n",
    "    t = t.unsqueeze(-1)\n",
    "\n",
    "    # 计算扩散过程中的 x(t)\n",
    "    a = alphas_bar_sqrt[t]\n",
    "    e = torch.randn_like(x_0)\n",
    "    aml = one_minus_alphas_bar_sqrt[t]\n",
    "\n",
    "    # 加噪声的输入\n",
    "    x = x_0 * a + e * aml\n",
    "\n",
    "    # 送入模型得到预测的噪声\n",
    "    t = t.to(x.device)\n",
    "    output = model(x, t.squeeze(-1))\n",
    "\n",
    "    # 计算损失：与真实噪声 e 的均方误差\n",
    "    return (e - output).square().mean()\n",
    "\n",
    "# 训练模型的函数\n",
    "def train(model, dataset, optimizer, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, num_epochs=4000):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_x in dataloader:\n",
    "            # 清空梯度\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 计算损失\n",
    "            loss = diffusion_loss_fn(model, batch_x, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, num_steps)\n",
    "\n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{num_epochs}, Loss: {loss.item()}\")\n",
    "    return loss\n",
    "\n",
    "# 采样函数：通过逆扩散生成数据\n",
    "def p_sample_loop(model, shape, n_steps, betas, one_minus_alphas_bar_sqrt):\n",
    "    cur_x = torch.randn(shape)\n",
    "    x_seq = [cur_x]\n",
    "    for i in reversed(range(n_steps)):\n",
    "        cur_x = p_sample(model, cur_x, i, betas, one_minus_alphas_bar_sqrt)\n",
    "        x_seq.append(cur_x)\n",
    "    return x_seq\n",
    "\n",
    "def p_sample(model, x, t, betas, one_minus_alphas_bar_sqrt):\n",
    "    t = torch.tensor(t).cuda()\n",
    "    x = torch.tensor(x).cuda()\n",
    "    coeff = betas[t] / one_minus_alphas_bar_sqrt[t]\n",
    "    eps_theta = model(x, t)\n",
    "    mean = (1 / torch.sqrt(1 - betas[t])) * (x - (coeff * eps_theta))\n",
    "    z = torch.randn_like(x)\n",
    "    sigma_t = torch.sqrt(betas[t])\n",
    "    sample = mean + sigma_t * z\n",
    "    return sample\n",
    "\n",
    "# 初始化模型、优化器和训练\n",
    "model = MLPDiffusion(num_steps, num_units=128).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "num_steps = 100\n",
    "filename = 'checkpoint0.ckpt'\n",
    "# 训练模型\n",
    "loss = train(model, dataset.cuda(), optimizer, alphas_bar_sqrt.cuda(), one_minus_alphas_bar_sqrt.cuda(), num_steps)\n",
    "\n",
    "save_checkpoint(model, optimizer, num_steps, loss, filename)\n",
    "\n",
    "# 生成样本\n",
    "load_checkpoint(model, optimizer, 'checkpoint0.ckpt')\n",
    "generated_samples = p_sample_loop(model, (1000, 3), num_steps, betas, one_minus_alphas_bar_sqrt)\n",
    "\n",
    "# 可视化生成的样本\n",
    "generated_samples = generated_samples[-1].cpu().detach().numpy()\n",
    "np.save('toy.npy', generated_samples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
