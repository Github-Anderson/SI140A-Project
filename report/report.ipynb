{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on Reverse Engineering the Mechanism of Wechat Red Envelop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generative Modeling\n",
    "For this section, we modify the diffusion model so as to learn the latent distribution behind the data and hence generate new data. The code supports running with GPU. The code is partially borrowed from the open tutorial resource published on github, and partial debugging is under the assistance of ChatGPT. We run the code on GPU of NVIDIA GeForce RTX 4070 Laptop, with the CPU of 13th Gen Intel(R) Core(TM) i9-13980HX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Code Implementaion\n",
    "The entire code is presented below. Here we support saving of the trained model and parameter designation through argparse. Again, it should be noted that the main idea of the neural network comes from diffusion model[1], partial code is borrowed from an open github repository, and partial debugging is under the assistance of ChatGPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load and preprocess data\n",
    "data = np.load('raw_data_2.npy')\n",
    "dataset = torch.Tensor(data).float().to(device)\n",
    "dimension = data.shape[1]\n",
    "print(\"The dimension of the data is: \", dimension, \" and the number of samples is: \", data.shape[0], 'The shape of the data is: ', data.shape)\n",
    "# Hyperparameters\n",
    "num_steps = 100  # Diffusion process time steps\n",
    "num_epochs = 4000  # Number of training epochs\n",
    "batch_size = 256  # Batch size\n",
    "\n",
    "# Create beta schedule (linearly increasing betas)\n",
    "betas = torch.linspace(1e-5, 0.5e-2, num_steps).to(device)\n",
    "\n",
    "# Compute alpha and related terms\n",
    "alphas = 1 - betas\n",
    "alphas_prod = torch.cumprod(alphas, dim=0)\n",
    "alphas_prod_p = torch.cat([torch.tensor([1.0], device=device), alphas_prod[:-1]], dim=0)\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod).to(device)\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod).to(device)\n",
    "\n",
    "# Noise addition function in diffusion process\n",
    "def q_x(x_0, t):\n",
    "    noise = torch.randn_like(x_0).to(device)  # Standard normal noise\n",
    "    alphas_t = alphas_bar_sqrt[t].unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "    alphas_l_m_t = one_minus_alphas_bar_sqrt[t].unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "    return alphas_t * x_0 + alphas_l_m_t * noise\n",
    "\n",
    "# Checkpoint functions\n",
    "def save_checkpoint(model, optimizer, epoch, loss, filename):\n",
    "    \"\"\"Save model and optimizer state.\"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"Checkpoint saved to {filename}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, filename, device):\n",
    "    \"\"\"Load model and optimizer state.\"\"\"\n",
    "    checkpoint = torch.load(filename, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Checkpoint loaded from {filename} at epoch {epoch} with loss {loss}\")\n",
    "    return epoch, loss\n",
    "\n",
    "# Define the MLP Diffusion model\n",
    "class MLPDiffusion(nn.Module):\n",
    "    def __init__(self, n_steps, dimension, num_units=128):\n",
    "        super(MLPDiffusion, self).__init__()\n",
    "        self.step_embedding = nn.Embedding(n_steps, num_units)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dimension + num_units, num_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units, num_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units, num_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_units, dimension),  # Output dimensions (x1, x2, x3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        t_embedding = self.step_embedding(t)  # Shape: (batch_size, num_units)\n",
    "        x = torch.cat([x, t_embedding], dim=1)  # Concatenate along feature dimension\n",
    "        return self.net(x)\n",
    "\n",
    "# Loss function: Mean Squared Error between predicted and true noise\n",
    "def diffusion_loss_fn(model, x_0, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, n_steps):\n",
    "    batch_size = x_0.shape[0]\n",
    "\n",
    "    # Randomly sample a timestep t for each example in the batch\n",
    "    t = torch.randint(0, n_steps, size=(batch_size,), device=device)\n",
    "\n",
    "    # Compute noisy input x(t)\n",
    "    a = alphas_bar_sqrt[t].unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "    e = torch.randn_like(x_0).to(device)  # Shape: (batch_size, 3)\n",
    "    aml = one_minus_alphas_bar_sqrt[t].unsqueeze(1)  # Shape: (batch_size, 1)\n",
    "    x = a * x_0 + aml * e  # Shape: (batch_size, 3)\n",
    "\n",
    "    # Predict the noise using the model\n",
    "    output = model(x, t)  # Shape: (batch_size, 3)\n",
    "\n",
    "    # Compute the loss (MSE between true noise and predicted noise)\n",
    "    return ((e - output) ** 2).mean()\n",
    "\n",
    "# Training function\n",
    "def train_model(model, dataset, optimizer, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, num_epochs):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for batch_x in dataloader:\n",
    "            batch_x = batch_x.to(device)\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Compute loss\n",
    "            loss = diffusion_loss_fn(model, batch_x, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, num_steps)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item() * batch_x.size(0)\n",
    "\n",
    "        epoch_loss /= len(dataloader.dataset)\n",
    "\n",
    "        if (epoch + 1) % 100 == 0 or epoch == num_epochs - 1:\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n",
    "\n",
    "    return epoch_loss\n",
    "\n",
    "# Sampling functions\n",
    "def p_sample(model, x, t, betas, one_minus_alphas_bar_sqrt, device):\n",
    "    # Compute coefficients and reshape to (batch_size, 1) for broadcasting\n",
    "    coeff = (betas[t] / one_minus_alphas_bar_sqrt[t]).unsqueeze(1)  # Shape: (1000, 1)\n",
    "    inv_sqrt_one_minus_betas = (1 / torch.sqrt(1 - betas[t])).unsqueeze(1)  # Shape: (1000, 1)\n",
    "    sqrt_betas = torch.sqrt(betas[t]).unsqueeze(1)  # Shape: (1000, 1)\n",
    "    \n",
    "    # Predict the noise using the model\n",
    "    eps_theta = model(x, t)  # Shape: (1000, 3)\n",
    "    \n",
    "    # Compute the mean\n",
    "    mean = inv_sqrt_one_minus_betas * (x - coeff * eps_theta)  # Shape: (1000, 3)\n",
    "    \n",
    "    # Sample noise for the current step\n",
    "    z = torch.randn_like(x).to(device)  # Shape: (1000, 3)\n",
    "    \n",
    "    # Compute the sample\n",
    "    sample = mean + sqrt_betas * z  # Shape: (1000, 3)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def p_sample_loop(model, shape, n_steps, betas, one_minus_alphas_bar_sqrt, device):\n",
    "    \"\"\"\n",
    "    Generate samples by iteratively applying p_sample.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        cur_x = torch.randn(shape).to(device)  # Initialize with random noise\n",
    "        x_seq = [cur_x]\n",
    "        for i in reversed(range(n_steps)):\n",
    "            t = torch.full((shape[0],), i, dtype=torch.long, device=device)  # Shape: (1000,)\n",
    "            cur_x = p_sample(model, cur_x, t, betas, one_minus_alphas_bar_sqrt, device)  # Shape: (1000, 3)\n",
    "            x_seq.append(cur_x)\n",
    "    return x_seq\n",
    "\n",
    "# Initialize model, optimizer, and train\n",
    "model = MLPDiffusion(num_steps, dimension, num_units=128).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "checkpoint_filename = 'checkpoint0.ckpt'\n",
    "\n",
    "# Train the model\n",
    "final_loss = train_model(model, dataset, optimizer, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, num_epochs)\n",
    "\n",
    "# Save the checkpoint\n",
    "save_checkpoint(model, optimizer, num_epochs, final_loss, checkpoint_filename)\n",
    "\n",
    "# Load the checkpoint (if needed)\n",
    "# load_checkpoint(model, optimizer, checkpoint_filename, device)\n",
    "\n",
    "# Generate samples\n",
    "generated_samples_seq = p_sample_loop(model, (1000, dimension), num_steps, betas, one_minus_alphas_bar_sqrt, device)\n",
    "\n",
    "# Extract the final generated samples\n",
    "generated_samples = generated_samples_seq[-1].cpu().detach().numpy()\n",
    "np.save('toy.npy', generated_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data stream and details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper of diffusion model[1], the pseudocode of the paradigm on training and sampling is presented as belows:\n",
    "<div style=\"display: flex; align-items: center;\">\n",
    "    <img src=\"image/pesudo1.png\"  style=\"margin-right: 10px;\">\n",
    "    <img src=\"image/pseudo2.png\" >\n",
    "</div>\n",
    "\n",
    "In the pseudocode above, $\\alpha_t = 1-\\beta_t$, $\\overline{\\alpha_t} = \\prod_{s-1}^t \\alpha_s$, where $\\beta$ denotes the beta schedule which increases linearly. $\\epsilon$ denotes noise and $x_0$ denotes the original data, meanwhile $x_T$ denotes that generated noise under normal distribution. Here we will apply the algorithm above to our specific task. \\\n",
    "The data stream and network component is presented in the figure below:\n",
    "\n",
    "![image](image/training_network.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
